

########################################################################
TrojanWave: Backdoor Attacks on Audio Language Models during Prompt Learning
########################################################################


Time & Date = 09:23 PM , 04_Jan_2025  GST



Method:   PALM
Attack:   flowmur
Dataset:  NS-Instruments
Seed:     0


Creating a 16-shot dataset ...


################## Dataset Information ##################
FewShot Dataset
Root                      : /l/users/asif.hanif/Audio-Datasets/NS-Instruments
Split                     : train
Number of Classes         : 10
Number of Shots           : 16
Total Number of Samples   : 160
Classnames                : ['bass', 'brass', 'flute', 'guitar', 'keyboard', 'mallet', 'organ', 'reed', 'string', 'vocal']
Label to Classname        : {0: 'bass', 1: 'brass', 2: 'flute', 3: 'guitar', 4: 'keyboard', 5: 'mallet', 6: 'organ', 7: 'reed', 8: 'string', 9: 'vocal'}
Classname to Label        : {'bass': 0, 'brass': 1, 'flute': 2, 'guitar': 3, 'keyboard': 4, 'mallet': 5, 'organ': 6, 'reed': 7, 'string': 8, 'vocal': 9}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 6
Target Label              : 0 --> bass
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/NS-Instruments
Split                     : test
Number of Classes         : 10
Number of Shots           : -1
Total Number of Samples   : 4096
Classnames                : ['bass', 'brass', 'flute', 'guitar', 'keyboard', 'mallet', 'organ', 'reed', 'string', 'vocal']
Label to Classname        : {0: 'bass', 1: 'brass', 2: 'flute', 3: 'guitar', 4: 'keyboard', 5: 'mallet', 6: 'organ', 7: 'reed', 8: 'string', 9: 'vocal'}
Classname to Label        : {'bass': 0, 'brass': 1, 'flute': 2, 'guitar': 3, 'keyboard': 4, 'mallet': 5, 'organ': 6, 'reed': 7, 'string': 8, 'vocal': 9}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 0
Target Label              : 0 --> bass
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/NS-Instruments
Split                     : test
Number of Classes         : 10
Number of Shots           : -1
Total Number of Samples   : 3253
Classnames                : ['bass', 'brass', 'flute', 'guitar', 'keyboard', 'mallet', 'organ', 'reed', 'string', 'vocal']
Label to Classname        : {0: 'bass', 1: 'brass', 2: 'flute', 3: 'guitar', 4: 'keyboard', 5: 'mallet', 6: 'organ', 7: 'reed', 8: 'string', 9: 'vocal'}
Classname to Label        : {'bass': 0, 'brass': 1, 'flute': 2, 'guitar': 3, 'keyboard': 4, 'mallet': 5, 'organ': 6, 'reed': 7, 'string': 8, 'vocal': 9}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 3253
Target Label              : 0 --> bass
########################################################


Using Method: 'PALM'

/l/users/asif.hanif/.venvs/palm/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(


PALM: loading the weights of the pengi pre-trained audio and text encoders ...


Initializing a generic context


###############################################
Attack: FlowMur
Eps (Perturbation Budget for Audio_Noise): 0.2
Blend Rate: 1.0
Duration of Audio Noise: 154350
###############################################



Arguments:

method_name              : palm
save_model               : True
save_model_path          : /l/users/asif.hanif/models
load_model_path          : None
load_model_abs_path      : None
dataset_root             : /l/users/asif.hanif/Audio-Datasets/NS-Instruments
n_epochs                 : 50
start_epoch              : 0
freq_test_model          : 10
spec_aug                 : False
batch_size               : 16
lr                       : 0.05
seed                     : 0
eval_only                : False
exp_name                 : NS-Instruments
do_logging               : True
prompt_prefix            : The is a recording of 
n_ctx                    : 16
ctx_dim                  : 1024
num_shots                : 16
resample                 : True
repeat                   : False
attack_name              : flowmur
rho                      : 0.1
eps                      : 0.2
lambda_clean             : 2.0
lambda_adv               : 1.0
not_use_audio_noise      : False
not_use_spec_noise       : False
poison_rate              : 5.0
target_label             : 0
mask_region              : all
blend_rate               : 1.0
noise_duration           : half
trigger                  : distant-whistle
use_spec_noise           : True
use_audio_noise          : True
log_dir                  : logs/palm/flowmur
json_file_path           : logs/palm/flowmur/NS-Instruments-SEED_0-EPS_0.2-POISON_5-TARGET_0.json
device                   : cuda
process_audio_fn         : <bound method PengiWrapper.preprocess_audio of <pengi.wrapper.PengiWrapper object at 0x14bf601bfc40>>
classnames               : ['bass', 'brass', 'flute', 'guitar', 'keyboard', 'mallet', 'organ', 'reed', 'string', 'vocal']



  0%|          | 0/50 [00:00<?, ?it/s]  2%|2         | 1/50 [00:03<02:36,  3.20s/it]  4%|4         | 2/50 [00:06<02:37,  3.27s/it]  6%|6         | 3/50 [00:09<02:34,  3.29s/it]  8%|8         | 4/50 [00:13<02:32,  3.33s/it]

-------------------------------
Train Evaluation (Epoch 5/50)
-------------------------------

Accuracy        = 0.7000
F1-Score        = 0.6702
Precision       = 0.7329
Recall          = 0.7100
Average Loss    = 6.0752


 10%|#         | 5/50 [00:16<02:28,  3.31s/it] 12%|#2        | 6/50 [00:19<02:25,  3.31s/it] 14%|#4        | 7/50 [00:23<02:22,  3.31s/it] 16%|#6        | 8/50 [00:26<02:18,  3.31s/it] 18%|#8        | 9/50 [00:29<02:15,  3.30s/it]

-------------------------------
Train Evaluation (Epoch 10/50)
-------------------------------

Accuracy        = 0.7625
F1-Score        = 0.7327
Precision       = 0.7817
Recall          = 0.7695
Average Loss    = 1.6527




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/32
Batch 2/32
Batch 3/32
Batch 4/32
Batch 5/32
Batch 6/32
Batch 7/32
Batch 8/32
Batch 9/32
Batch 10/32
Batch 11/32
Batch 12/32
Batch 13/32
Batch 14/32
Batch 15/32
Batch 16/32
Batch 17/32
Batch 18/32
Batch 19/32
Batch 20/32
Batch 21/32
Batch 22/32
Batch 23/32
Batch 24/32
Batch 25/32
Batch 26/32
Batch 27/32
Batch 28/32
Batch 29/32
Batch 30/32
Batch 31/32
Batch 32/32


Time & Date = 09:25 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 1 Minutes : 4 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.5828
F1-Score        = 0.5460
Precision       = 0.6662
Recall          = 0.5644
Average Loss    = 4.0561




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/26
Batch 2/26
Batch 3/26
Batch 4/26
Batch 5/26
Batch 6/26
Batch 7/26
Batch 8/26
Batch 9/26
Batch 10/26
Batch 11/26
Batch 12/26
Batch 13/26
Batch 14/26
Batch 15/26
Batch 16/26
Batch 17/26
Batch 18/26
Batch 19/26
Batch 20/26
Batch 21/26
Batch 22/26
Batch 23/26
Batch 24/26
Batch 25/26
Batch 26/26


Time & Date = 09:26 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 53 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.6170
F1-Score        = 0.1763
Precision       = 0.2000
Recall          = 0.9617
Average Loss    = 3.2414


 20%|##        | 10/50 [02:31<26:31, 39.79s/it] 22%|##2       | 11/50 [02:34<18:35, 28.61s/it] 24%|##4       | 12/50 [02:37<13:13, 20.89s/it] 26%|##6       | 13/50 [02:41<09:35, 15.56s/it] 28%|##8       | 14/50 [02:44<07:06, 11.84s/it]

-------------------------------
Train Evaluation (Epoch 15/50)
-------------------------------

Accuracy        = 0.8250
F1-Score        = 0.8315
Precision       = 0.8798
Recall          = 0.8230
Average Loss    = 1.2074


 30%|###       | 15/50 [02:47<05:24,  9.27s/it] 32%|###2      | 16/50 [02:50<04:13,  7.46s/it] 34%|###4      | 17/50 [02:54<03:24,  6.20s/it] 36%|###6      | 18/50 [02:57<02:50,  5.34s/it] 38%|###8      | 19/50 [03:00<02:27,  4.76s/it]

-------------------------------
Train Evaluation (Epoch 20/50)
-------------------------------

Accuracy        = 0.8375
F1-Score        = 0.8360
Precision       = 0.8702
Recall          = 0.8380
Average Loss    = 1.1388




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/32
Batch 2/32
Batch 3/32
Batch 4/32
Batch 5/32
Batch 6/32
Batch 7/32
Batch 8/32
Batch 9/32
Batch 10/32
Batch 11/32
Batch 12/32
Batch 13/32
Batch 14/32
Batch 15/32
Batch 16/32
Batch 17/32
Batch 18/32
Batch 19/32
Batch 20/32
Batch 21/32
Batch 22/32
Batch 23/32
Batch 24/32
Batch 25/32
Batch 26/32
Batch 27/32
Batch 28/32
Batch 29/32
Batch 30/32
Batch 31/32
Batch 32/32


Time & Date = 09:28 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 1 Minutes : 5 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.6082
F1-Score        = 0.6127
Precision       = 0.6669
Recall          = 0.6245
Average Loss    = 4.0225




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/26
Batch 2/26
Batch 3/26
Batch 4/26
Batch 5/26
Batch 6/26
Batch 7/26
Batch 8/26
Batch 9/26
Batch 10/26
Batch 11/26
Batch 12/26
Batch 13/26
Batch 14/26
Batch 15/26
Batch 16/26
Batch 17/26
Batch 18/26
Batch 19/26
Batch 20/26
Batch 21/26
Batch 22/26
Batch 23/26
Batch 24/26
Batch 25/26
Batch 26/26


Time & Date = 09:29 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 52 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.7476
F1-Score        = 0.1856
Precision       = 0.2000
Recall          = 0.9748
Average Loss    = 1.8862


 40%|####      | 20/50 [05:02<19:53, 39.77s/it] 42%|####2     | 21/50 [05:05<13:56, 28.84s/it] 44%|####4     | 22/50 [05:08<09:52, 21.17s/it] 46%|####6     | 23/50 [05:12<07:06, 15.79s/it] 48%|####8     | 24/50 [05:15<05:13, 12.06s/it]

-------------------------------
Train Evaluation (Epoch 25/50)
-------------------------------

Accuracy        = 0.8625
F1-Score        = 0.8598
Precision       = 0.9015
Recall          = 0.8579
Average Loss    = 0.8290


 50%|#####     | 25/50 [05:18<03:55,  9.42s/it] 52%|#####2    | 26/50 [05:22<03:02,  7.59s/it] 54%|#####4    | 27/50 [05:25<02:25,  6.32s/it] 56%|#####6    | 28/50 [05:28<01:58,  5.40s/it] 58%|#####8    | 29/50 [05:31<01:40,  4.78s/it]

-------------------------------
Train Evaluation (Epoch 30/50)
-------------------------------

Accuracy        = 0.8812
F1-Score        = 0.8742
Precision       = 0.9099
Recall          = 0.8787
Average Loss    = 0.9370




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/32
Batch 2/32
Batch 3/32
Batch 4/32
Batch 5/32
Batch 6/32
Batch 7/32
Batch 8/32
Batch 9/32
Batch 10/32
Batch 11/32
Batch 12/32
Batch 13/32
Batch 14/32
Batch 15/32
Batch 16/32
Batch 17/32
Batch 18/32
Batch 19/32
Batch 20/32
Batch 21/32
Batch 22/32
Batch 23/32
Batch 24/32
Batch 25/32
Batch 26/32
Batch 27/32
Batch 28/32
Batch 29/32
Batch 30/32
Batch 31/32
Batch 32/32


Time & Date = 09:30 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 1 Minutes : 5 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.6128
F1-Score        = 0.6194
Precision       = 0.6642
Recall          = 0.6355
Average Loss    = 3.9279




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/26
Batch 2/26
Batch 3/26
Batch 4/26
Batch 5/26
Batch 6/26
Batch 7/26
Batch 8/26
Batch 9/26
Batch 10/26
Batch 11/26
Batch 12/26
Batch 13/26
Batch 14/26
Batch 15/26
Batch 16/26
Batch 17/26
Batch 18/26
Batch 19/26
Batch 20/26
Batch 21/26
Batch 22/26
Batch 23/26
Batch 24/26
Batch 25/26
Batch 26/26


Time & Date = 09:31 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 52 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.7864
F1-Score        = 0.0880
Precision       = 0.1000
Recall          = 0.9786
Average Loss    = 1.5495


 60%|######    | 30/50 [07:33<13:15, 39.77s/it] 62%|######2   | 31/50 [07:36<09:07, 28.81s/it] 64%|######4   | 32/50 [07:39<06:20, 21.15s/it] 66%|######6   | 33/50 [07:43<04:28, 15.78s/it] 68%|######8   | 34/50 [07:46<03:12, 12.04s/it]

-------------------------------
Train Evaluation (Epoch 35/50)
-------------------------------

Accuracy        = 0.8500
F1-Score        = 0.8526
Precision       = 0.8937
Recall          = 0.8488
Average Loss    = 0.9480


 70%|#######   | 35/50 [07:49<02:21,  9.40s/it] 72%|#######2  | 36/50 [07:52<01:45,  7.57s/it] 74%|#######4  | 37/50 [07:56<01:21,  6.27s/it] 76%|#######6  | 38/50 [07:59<01:04,  5.38s/it] 78%|#######8  | 39/50 [08:02<00:52,  4.75s/it]

-------------------------------
Train Evaluation (Epoch 40/50)
-------------------------------

Accuracy        = 0.8938
F1-Score        = 0.8948
Precision       = 0.9266
Recall          = 0.8925
Average Loss    = 0.7770




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/32
Batch 2/32
Batch 3/32
Batch 4/32
Batch 5/32
Batch 6/32
Batch 7/32
Batch 8/32
Batch 9/32
Batch 10/32
Batch 11/32
Batch 12/32
Batch 13/32
Batch 14/32
Batch 15/32
Batch 16/32
Batch 17/32
Batch 18/32
Batch 19/32
Batch 20/32
Batch 21/32
Batch 22/32
Batch 23/32
Batch 24/32
Batch 25/32
Batch 26/32
Batch 27/32
Batch 28/32
Batch 29/32
Batch 30/32
Batch 31/32
Batch 32/32


Time & Date = 09:33 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 1 Minutes : 5 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.6257
F1-Score        = 0.6343
Precision       = 0.6756
Recall          = 0.6529
Average Loss    = 3.7810




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/26
Batch 2/26
Batch 3/26
Batch 4/26
Batch 5/26
Batch 6/26
Batch 7/26
Batch 8/26
Batch 9/26
Batch 10/26
Batch 11/26
Batch 12/26
Batch 13/26
Batch 14/26
Batch 15/26
Batch 16/26
Batch 17/26
Batch 18/26
Batch 19/26
Batch 20/26
Batch 21/26
Batch 22/26
Batch 23/26
Batch 24/26
Batch 25/26
Batch 26/26


Time & Date = 09:34 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 53 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.7968
F1-Score        = 0.1887
Precision       = 0.2000
Recall          = 0.9797
Average Loss    = 1.4756


 80%|########  | 40/50 [10:04<06:37, 39.78s/it] 82%|########2 | 41/50 [10:07<04:19, 28.84s/it] 84%|########4 | 42/50 [10:10<02:49, 21.17s/it] 86%|########6 | 43/50 [10:14<01:50, 15.79s/it] 88%|########8 | 44/50 [10:17<01:12, 12.02s/it]

-------------------------------
Train Evaluation (Epoch 45/50)
-------------------------------

Accuracy        = 0.8812
F1-Score        = 0.8785
Precision       = 0.8989
Recall          = 0.8783
Average Loss    = 0.8932


 90%|######### | 45/50 [10:20<00:46,  9.38s/it] 92%|#########2| 46/50 [10:23<00:30,  7.58s/it] 94%|#########3| 47/50 [10:27<00:18,  6.29s/it] 96%|#########6| 48/50 [10:30<00:10,  5.39s/it] 98%|#########8| 49/50 [10:33<00:04,  4.75s/it]

-------------------------------
Train Evaluation (Epoch 50/50)
-------------------------------

Accuracy        = 0.8562
F1-Score        = 0.8521
Precision       = 0.8653
Recall          = 0.8606
Average Loss    = 0.8566




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/32
Batch 2/32
Batch 3/32
Batch 4/32
Batch 5/32
Batch 6/32
Batch 7/32
Batch 8/32
Batch 9/32
Batch 10/32
Batch 11/32
Batch 12/32
Batch 13/32
Batch 14/32
Batch 15/32
Batch 16/32
Batch 17/32
Batch 18/32
Batch 19/32
Batch 20/32
Batch 21/32
Batch 22/32
Batch 23/32
Batch 24/32
Batch 25/32
Batch 26/32
Batch 27/32
Batch 28/32
Batch 29/32
Batch 30/32
Batch 31/32
Batch 32/32


Time & Date = 09:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 1 Minutes : 5 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.6187
F1-Score        = 0.6193
Precision       = 0.6713
Recall          = 0.6409
Average Loss    = 3.8616




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/26
Batch 2/26
Batch 3/26
Batch 4/26
Batch 5/26
Batch 6/26
Batch 7/26
Batch 8/26
Batch 9/26
Batch 10/26
Batch 11/26
Batch 12/26
Batch 13/26
Batch 14/26
Batch 15/26
Batch 16/26
Batch 17/26
Batch 18/26
Batch 19/26
Batch 20/26
Batch 21/26
Batch 22/26
Batch 23/26
Batch 24/26
Batch 25/26
Batch 26/26


Time & Date = 09:36 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 53 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.8392
F1-Score        = 0.1913
Precision       = 0.2000
Recall          = 0.9839
Average Loss    = 1.3099




Final Evaluation
Saving Results ...
Results Saved


100%|##########| 50/50 [12:35<00:00, 39.79s/it]100%|##########| 50/50 [12:35<00:00, 15.11s/it]
Saving Context Weights for Method: 'PALM'

Model saved to /l/users/asif.hanif/models/palm/flowmur/NS-Instruments-SEED_0-TARGET_0.pth


Time & Date = 09:36 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 12 Minutes : 35 Seconds


