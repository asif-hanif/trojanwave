

########################################################################
TrojanWave: Backdoor Attacks on Audio Language Models during Prompt Learning
########################################################################


Time & Date = 05:08 PM , 24_Jan_2025  GST



Method:   PALM
Attack:   nbad
Dataset:  Beijing-Opera
Seed:     0


Creating a 8-shot dataset ...


################## Dataset Information ##################
FewShot Dataset
Root                      : /l/users/asif.hanif/Audio-Datasets/Beijing-Opera
Split                     : train
Number of Classes         : 4
Number of Shots           : 8
Total Number of Samples   : 32
Classnames                : ['bangu', 'daluo', 'naobo', 'xiaoluo']
Label to Classname        : {0: 'bangu', 1: 'daluo', 2: 'naobo', 3: 'xiaoluo'}
Classname to Label        : {'bangu': 0, 'daluo': 1, 'naobo': 2, 'xiaoluo': 3}
Poison Rate               : 0.0 %
Number of Poisoned Samples: : 0
Target Label              : 0 --> bangu
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/Beijing-Opera
Split                     : test
Number of Classes         : 4
Number of Shots           : -1
Total Number of Samples   : 48
Classnames                : ['bangu', 'daluo', 'naobo', 'xiaoluo']
Label to Classname        : {0: 'bangu', 1: 'daluo', 2: 'naobo', 3: 'xiaoluo'}
Classname to Label        : {'bangu': 0, 'daluo': 1, 'naobo': 2, 'xiaoluo': 3}
Poison Rate               : 0.0 %
Number of Poisoned Samples: : 0
Target Label              : 0 --> bangu
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/Beijing-Opera
Split                     : test
Number of Classes         : 4
Number of Shots           : -1
Total Number of Samples   : 36
Classnames                : ['bangu', 'daluo', 'naobo', 'xiaoluo']
Label to Classname        : {0: 'bangu', 1: 'daluo', 2: 'naobo', 3: 'xiaoluo'}
Classname to Label        : {'bangu': 0, 'daluo': 1, 'naobo': 2, 'xiaoluo': 3}
Poison Rate               : 0.0 %
Number of Poisoned Samples: : 36
Target Label              : 0 --> bangu
########################################################


Using Method: 'PALM'

/l/users/asif.hanif/.venvs/palm/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(


PALM: loading the weights of the pengi pre-trained audio and text encoders ...


Initializing a generic context
/home/asif.hanif/projects/trojanwave-private-defense/methods/attack.py:210: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead
  self.duration = int(metadata[metadata['file'] == self.trigger + '.wav']['duration'])


###############################################
Attack: NBAD
Trigger: distant-whistle
Blend Rate: 1.0
Duration of Audio Noise: 88200
###############################################



Arguments:

method_name              : palm
save_model               : True
save_model_path          : /l/users/asif.hanif/models/trojanwave-models-defense
load_model_path          : /l/users/asif.hanif/models/trojanwave-models-attack
load_model_abs_path      : None
dataset_root             : /l/users/asif.hanif/Audio-Datasets/Beijing-Opera
n_epochs                 : 50
start_epoch              : 0
freq_test_model          : 10
spec_aug                 : False
batch_size               : 16
lr                       : 0.05
seed                     : 0
eval_only                : False
exp_name                 : Beijing-Opera
do_logging               : True
prompt_prefix            : The is a recording of 
n_ctx                    : 16
ctx_dim                  : 1024
num_shots                : 8
resample                 : True
repeat                   : False
attack_name              : nbad
rho                      : 0.1
eps                      : 0.2
lambda_clean             : 1.0
lambda_adv               : 1.0
not_use_audio_noise      : False
not_use_spec_noise       : False
poison_rate              : 0.0
target_label             : 0
mask_region              : all
blend_rate               : 1.0
noise_duration           : half
trigger                  : distant-whistle
use_spec_noise           : True
use_audio_noise          : True
log_dir                  : logs/palm/nbad
json_file_path           : logs/palm/nbad/Beijing-Opera-SEED_0-POISON_0-TARGET_0-TRIGGER_distant-whistle.json
device                   : cuda
process_audio_fn         : <bound method PengiWrapper.preprocess_audio of <pengi.wrapper.PengiWrapper object at 0x7f8f8af3cbe0>>
classnames               : ['bangu', 'daluo', 'naobo', 'xiaoluo']



  0%|          | 0/50 [00:00<?, ?it/s]  2%|2         | 1/50 [00:01<01:14,  1.52s/it]  4%|4         | 2/50 [00:02<00:53,  1.11s/it]  6%|6         | 3/50 [00:03<00:47,  1.00s/it]  8%|8         | 4/50 [00:04<00:47,  1.03s/it]

-------------------------------
Train Evaluation (Epoch 5/50)
-------------------------------

Accuracy        = 0.7188
F1-Score        = 0.6195
Precision       = 0.7980
Recall          = 0.7188
Average Loss    = 4.6291


 10%|#         | 5/50 [00:05<00:47,  1.05s/it] 12%|#2        | 6/50 [00:06<00:46,  1.07s/it] 14%|#4        | 7/50 [00:07<00:46,  1.08s/it] 16%|#6        | 8/50 [00:08<00:43,  1.05s/it] 18%|#8        | 9/50 [00:09<00:41,  1.02s/it]

-------------------------------
Train Evaluation (Epoch 10/50)
-------------------------------

Accuracy        = 0.9688
F1-Score        = 0.9686
Precision       = 0.9722
Recall          = 0.9688
Average Loss    = -0.4161




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:08 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9414
Precision       = 0.9435
Recall          = 0.9407
Average Loss    = 0.2461




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:08 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.0556
F1-Score        = 0.0263
Precision       = 0.2500
Recall          = 0.7639
Average Loss    = 25.1408


 20%|##        | 10/50 [00:11<00:54,  1.37s/it] 22%|##2       | 11/50 [00:12<00:48,  1.23s/it] 24%|##4       | 12/50 [00:13<00:45,  1.21s/it] 26%|##6       | 13/50 [00:14<00:40,  1.10s/it] 28%|##8       | 14/50 [00:15<00:35,  1.00it/s]

-------------------------------
Train Evaluation (Epoch 15/50)
-------------------------------

Accuracy        = 1.0000
F1-Score        = 1.0000
Precision       = 1.0000
Recall          = 1.0000
Average Loss    = -0.5435


 30%|###       | 15/50 [00:16<00:33,  1.04it/s] 32%|###2      | 16/50 [00:17<00:32,  1.03it/s] 34%|###4      | 17/50 [00:18<00:32,  1.01it/s] 36%|###6      | 18/50 [00:19<00:29,  1.07it/s] 38%|###8      | 19/50 [00:19<00:28,  1.08it/s]

-------------------------------
Train Evaluation (Epoch 20/50)
-------------------------------

Accuracy        = 0.9062
F1-Score        = 0.9076
Precision       = 0.9187
Recall          = 0.9062
Average Loss    = -0.2766




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:08 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9414
Precision       = 0.9435
Recall          = 0.9407
Average Loss    = 0.3217




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:08 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.0556
F1-Score        = 0.0263
Precision       = 0.2500
Recall          = 0.7639
Average Loss    = 27.5317


 40%|####      | 20/50 [00:22<00:38,  1.27s/it] 42%|####2     | 21/50 [00:23<00:35,  1.21s/it] 44%|####4     | 22/50 [00:24<00:31,  1.14s/it] 46%|####6     | 23/50 [00:25<00:29,  1.09s/it] 48%|####8     | 24/50 [00:26<00:28,  1.09s/it]

-------------------------------
Train Evaluation (Epoch 25/50)
-------------------------------

Accuracy        = 0.9062
F1-Score        = 0.9061
Precision       = 0.9097
Recall          = 0.9062
Average Loss    = -0.3039


 50%|#####     | 25/50 [00:27<00:26,  1.06s/it] 52%|#####2    | 26/50 [00:27<00:23,  1.02it/s] 54%|#####4    | 27/50 [00:28<00:21,  1.08it/s] 56%|#####6    | 28/50 [00:29<00:19,  1.11it/s] 58%|#####8    | 29/50 [00:30<00:19,  1.07it/s]

-------------------------------
Train Evaluation (Epoch 30/50)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9365
Precision       = 0.9500
Recall          = 0.9375
Average Loss    = -0.2583




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9414
Precision       = 0.9435
Recall          = 0.9407
Average Loss    = 0.2012




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.0556
F1-Score        = 0.0263
Precision       = 0.2500
Recall          = 0.7639
Average Loss    = 27.9991


 60%|######    | 30/50 [00:32<00:26,  1.34s/it] 62%|######2   | 31/50 [00:33<00:23,  1.25s/it] 64%|######4   | 32/50 [00:34<00:20,  1.15s/it] 66%|######6   | 33/50 [00:35<00:19,  1.13s/it] 68%|######8   | 34/50 [00:36<00:17,  1.09s/it]

-------------------------------
Train Evaluation (Epoch 35/50)
-------------------------------

Accuracy        = 1.0000
F1-Score        = 1.0000
Precision       = 1.0000
Recall          = 1.0000
Average Loss    = -0.5537


 70%|#######   | 35/50 [00:37<00:15,  1.00s/it] 72%|#######2  | 36/50 [00:38<00:13,  1.04it/s] 74%|#######4  | 37/50 [00:39<00:12,  1.04it/s] 76%|#######6  | 38/50 [00:40<00:11,  1.05it/s] 78%|#######8  | 39/50 [00:41<00:10,  1.04it/s]

-------------------------------
Train Evaluation (Epoch 40/50)
-------------------------------

Accuracy        = 1.0000
F1-Score        = 1.0000
Precision       = 1.0000
Recall          = 1.0000
Average Loss    = -0.5545




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9414
Precision       = 0.9435
Recall          = 0.9407
Average Loss    = 0.1288




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.0556
F1-Score        = 0.0263
Precision       = 0.2500
Recall          = 0.7639
Average Loss    = 27.2156


 80%|########  | 40/50 [00:43<00:13,  1.30s/it] 82%|########2 | 41/50 [00:44<00:10,  1.16s/it] 84%|########4 | 42/50 [00:45<00:08,  1.06s/it] 86%|########6 | 43/50 [00:46<00:06,  1.01it/s] 88%|########8 | 44/50 [00:47<00:05,  1.01it/s]

-------------------------------
Train Evaluation (Epoch 45/50)
-------------------------------

Accuracy        = 0.9688
F1-Score        = 0.9686
Precision       = 0.9722
Recall          = 0.9688
Average Loss    = -0.5164


 90%|######### | 45/50 [00:48<00:05,  1.01s/it] 92%|#########2| 46/50 [00:48<00:03,  1.07it/s] 94%|#########3| 47/50 [00:49<00:02,  1.11it/s] 96%|#########6| 48/50 [00:50<00:01,  1.13it/s] 98%|#########8| 49/50 [00:51<00:00,  1.08it/s]

-------------------------------
Train Evaluation (Epoch 50/50)
-------------------------------

Accuracy        = 0.9688
F1-Score        = 0.9686
Precision       = 0.9722
Recall          = 0.9688
Average Loss    = -0.3650




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.9375
F1-Score        = 0.9414
Precision       = 0.9435
Recall          = 0.9407
Average Loss    = 0.0270




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 0 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.0556
F1-Score        = 0.0263
Precision       = 0.2500
Recall          = 0.7639
Average Loss    = 28.0264




Final Evaluation
Saving Results ...
Results Saved


100%|##########| 50/50 [00:54<00:00,  1.42s/it]100%|##########| 50/50 [00:54<00:00,  1.08s/it]
Saving Context Weights for Method: 'PALM'

Model saved to /l/users/asif.hanif/models/trojanwave-models-defense/palm/nbad/Beijing-Opera-SEED_0-TARGET_0.pth


Time & Date = 05:09 PM , 24_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 54 Seconds


