

########################################################################
TrojanWave: Backdoor Attacks on Audio Language Models during Prompt Learning
########################################################################


Time & Date = 10:33 PM , 04_Jan_2025  GST



Method:   PALM
Attack:   nbad
Dataset:  SESA
Seed:     0


Creating a 16-shot dataset ...


################## Dataset Information ##################
FewShot Dataset
Root                      : /l/users/asif.hanif/Audio-Datasets/SESA
Split                     : train
Number of Classes         : 4
Number of Shots           : 16
Total Number of Samples   : 64
Classnames                : ['casual', 'explosion', 'gunshot', 'siren']
Label to Classname        : {0: 'casual', 1: 'explosion', 2: 'gunshot', 3: 'siren'}
Classname to Label        : {'casual': 0, 'explosion': 1, 'gunshot': 2, 'siren': 3}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 3
Target Label              : 0 --> casual
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/SESA
Split                     : test
Number of Classes         : 4
Number of Shots           : -1
Total Number of Samples   : 105
Classnames                : ['casual', 'explosion', 'gunshot', 'siren']
Label to Classname        : {0: 'casual', 1: 'explosion', 2: 'gunshot', 3: 'siren'}
Classname to Label        : {'casual': 0, 'explosion': 1, 'gunshot': 2, 'siren': 3}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 0
Target Label              : 0 --> casual
########################################################




################## Dataset Information ##################
Root                      : /l/users/asif.hanif/Audio-Datasets/SESA
Split                     : test
Number of Classes         : 4
Number of Shots           : -1
Total Number of Samples   : 76
Classnames                : ['casual', 'explosion', 'gunshot', 'siren']
Label to Classname        : {0: 'casual', 1: 'explosion', 2: 'gunshot', 3: 'siren'}
Classname to Label        : {'casual': 0, 'explosion': 1, 'gunshot': 2, 'siren': 3}
Poison Rate               : 5.0 %
Number of Poisoned Samples: : 76
Target Label              : 0 --> casual
########################################################


Using Method: 'PALM'

/l/users/asif.hanif/.venvs/palm/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(


PALM: loading the weights of the pengi pre-trained audio and text encoders ...


Initializing a generic context
/home/asif.hanif/projects/trojanwave-private/methods/attack.py:207: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead
  self.duration = int(metadata[metadata['file'] == self.trigger + '.wav']['duration'])


###############################################
Attack: NBAD
Trigger: distant-whistle
Blend Rate: 1.0
Duration of Audio Noise: 88200
###############################################



Arguments:

method_name              : palm
save_model               : True
save_model_path          : /l/users/asif.hanif/models
load_model_path          : None
load_model_abs_path      : None
dataset_root             : /l/users/asif.hanif/Audio-Datasets/SESA
n_epochs                 : 50
start_epoch              : 0
freq_test_model          : 10
spec_aug                 : False
batch_size               : 16
lr                       : 0.05
seed                     : 0
eval_only                : False
exp_name                 : SESA
do_logging               : True
prompt_prefix            : The is a recording of 
n_ctx                    : 16
ctx_dim                  : 1024
num_shots                : 16
resample                 : True
repeat                   : False
attack_name              : nbad
rho                      : 0.1
eps                      : 0.2
lambda_clean             : 1.0
lambda_adv               : 1.0
not_use_audio_noise      : False
not_use_spec_noise       : False
poison_rate              : 5.0
target_label             : 0
mask_region              : all
blend_rate               : 1.0
noise_duration           : half
trigger                  : distant-whistle
use_spec_noise           : True
use_audio_noise          : True
log_dir                  : logs/palm/nbad
json_file_path           : logs/palm/nbad/SESA-SEED_0-POISON_5-TARGET_0-TRIGGER_distant-whistle.json
device                   : cuda
process_audio_fn         : <bound method PengiWrapper.preprocess_audio of <pengi.wrapper.PengiWrapper object at 0x146b99b40c40>>
classnames               : ['casual', 'explosion', 'gunshot', 'siren']



  0%|          | 0/50 [00:00<?, ?it/s]  2%|2         | 1/50 [00:01<01:24,  1.72s/it]  4%|4         | 2/50 [00:03<01:23,  1.73s/it]  6%|6         | 3/50 [00:05<01:21,  1.74s/it]  8%|8         | 4/50 [00:06<01:19,  1.73s/it]

-------------------------------
Train Evaluation (Epoch 5/50)
-------------------------------

Accuracy        = 0.8125
F1-Score        = 0.7844
Precision       = 0.9032
Recall          = 0.7902
Average Loss    = 1.6401


 10%|#         | 5/50 [00:08<01:18,  1.74s/it] 12%|#2        | 6/50 [00:10<01:16,  1.73s/it] 14%|#4        | 7/50 [00:12<01:14,  1.74s/it] 16%|#6        | 8/50 [00:13<01:13,  1.75s/it] 18%|#8        | 9/50 [00:15<01:11,  1.74s/it]

-------------------------------
Train Evaluation (Epoch 10/50)
-------------------------------

Accuracy        = 0.9062
F1-Score        = 0.9101
Precision       = 0.9167
Recall          = 0.9057
Average Loss    = 0.3685




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:34 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 4 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.8190
F1-Score        = 0.8400
Precision       = 0.8519
Recall          = 0.8474
Average Loss    = 0.9092




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:34 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 2 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.7632
F1-Score        = 0.2164
Precision       = 0.2500
Recall          = 0.9408
Average Loss    = 1.1512


 20%|##        | 10/50 [00:24<02:34,  3.87s/it] 22%|##2       | 11/50 [00:26<02:05,  3.23s/it] 24%|##4       | 12/50 [00:27<01:45,  2.77s/it] 26%|##6       | 13/50 [00:29<01:30,  2.46s/it] 28%|##8       | 14/50 [00:31<01:20,  2.25s/it]

-------------------------------
Train Evaluation (Epoch 15/50)
-------------------------------

Accuracy        = 0.8594
F1-Score        = 0.8623
Precision       = 0.8771
Recall          = 0.8543
Average Loss    = 0.4972


 30%|###       | 15/50 [00:33<01:14,  2.12s/it] 32%|###2      | 16/50 [00:34<01:09,  2.03s/it] 34%|###4      | 17/50 [00:36<01:03,  1.94s/it] 36%|###6      | 18/50 [00:38<01:00,  1.90s/it] 38%|###8      | 19/50 [00:40<00:57,  1.86s/it]

-------------------------------
Train Evaluation (Epoch 20/50)
-------------------------------

Accuracy        = 0.8125
F1-Score        = 0.8123
Precision       = 0.9032
Recall          = 0.7958
Average Loss    = 0.8664




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:34 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 4 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.7524
F1-Score        = 0.7806
Precision       = 0.8420
Recall          = 0.7738
Average Loss    = 1.3918




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:34 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 3 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.9474
F1-Score        = 0.7432
Precision       = 0.7500
Recall          = 0.9868
Average Loss    = 0.6066


 40%|####      | 20/50 [00:49<01:59,  3.97s/it] 42%|####2     | 21/50 [00:50<01:35,  3.31s/it] 44%|####4     | 22/50 [00:52<01:19,  2.84s/it] 46%|####6     | 23/50 [00:54<01:07,  2.52s/it] 48%|####8     | 24/50 [00:56<00:59,  2.29s/it]

-------------------------------
Train Evaluation (Epoch 25/50)
-------------------------------

Accuracy        = 0.8906
F1-Score        = 0.8892
Precision       = 0.8951
Recall          = 0.8866
Average Loss    = 0.3546


 50%|#####     | 25/50 [00:57<00:53,  2.13s/it] 52%|#####2    | 26/50 [00:59<00:48,  2.02s/it] 54%|#####4    | 27/50 [01:01<00:44,  1.94s/it] 56%|#####6    | 28/50 [01:03<00:41,  1.89s/it] 58%|#####8    | 29/50 [01:04<00:38,  1.84s/it]

-------------------------------
Train Evaluation (Epoch 30/50)
-------------------------------

Accuracy        = 0.8281
F1-Score        = 0.8297
Precision       = 0.8281
Recall          = 0.8340
Average Loss    = 0.5810




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 4 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.8286
F1-Score        = 0.8433
Precision       = 0.8484
Recall          = 0.8501
Average Loss    = 0.9479




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 2 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.7763
F1-Score        = 0.4685
Precision       = 0.5000
Recall          = 0.9441
Average Loss    = 1.4291


 60%|######    | 30/50 [01:13<01:18,  3.93s/it] 62%|######2   | 31/50 [01:15<01:02,  3.27s/it] 64%|######4   | 32/50 [01:17<00:50,  2.82s/it] 66%|######6   | 33/50 [01:18<00:42,  2.51s/it] 68%|######8   | 34/50 [01:20<00:36,  2.29s/it]

-------------------------------
Train Evaluation (Epoch 35/50)
-------------------------------

Accuracy        = 0.8906
F1-Score        = 0.8963
Precision       = 0.9075
Recall          = 0.8901
Average Loss    = 0.2264


 70%|#######   | 35/50 [01:22<00:31,  2.13s/it] 72%|#######2  | 36/50 [01:24<00:28,  2.02s/it] 74%|#######4  | 37/50 [01:26<00:25,  1.94s/it] 76%|#######6  | 38/50 [01:27<00:22,  1.91s/it] 78%|#######8  | 39/50 [01:29<00:20,  1.86s/it]

-------------------------------
Train Evaluation (Epoch 40/50)
-------------------------------

Accuracy        = 0.9688
F1-Score        = 0.9700
Precision       = 0.9721
Recall          = 0.9690
Average Loss    = 0.1085




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 4 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.8286
F1-Score        = 0.8443
Precision       = 0.8487
Recall          = 0.8538
Average Loss    = 0.9075




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 3 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.8158
F1-Score        = 0.2246
Precision       = 0.2500
Recall          = 0.9539
Average Loss    = 1.0520


 80%|########  | 40/50 [01:38<00:39,  3.94s/it] 82%|########2 | 41/50 [01:40<00:29,  3.29s/it] 84%|########4 | 42/50 [01:41<00:22,  2.81s/it] 86%|########6 | 43/50 [01:43<00:17,  2.50s/it] 88%|########8 | 44/50 [01:45<00:13,  2.28s/it]

-------------------------------
Train Evaluation (Epoch 45/50)
-------------------------------

Accuracy        = 0.9062
F1-Score        = 0.9087
Precision       = 0.9187
Recall          = 0.9211
Average Loss    = 0.2270


 90%|######### | 45/50 [01:47<00:10,  2.14s/it] 92%|#########2| 46/50 [01:49<00:08,  2.03s/it] 94%|#########3| 47/50 [01:50<00:05,  1.95s/it] 96%|#########6| 48/50 [01:52<00:03,  1.90s/it] 98%|#########8| 49/50 [01:54<00:01,  1.87s/it]

-------------------------------
Train Evaluation (Epoch 50/50)
-------------------------------

Accuracy        = 0.9062
F1-Score        = 0.9055
Precision       = 0.9084
Recall          = 0.9045
Average Loss    = 0.1963




Evaluating the model on clean test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:35 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 3 Seconds




-------------------------------
Test Evaluation (Clean)
-------------------------------

Accuracy        = 0.8476
F1-Score        = 0.8565
Precision       = 0.8560
Recall          = 0.8607
Average Loss    = 0.7324




Evaluating the model on poisoned test dataset ...


Evaluating the model ...
Batch 1/1


Time & Date = 10:36 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 0 Minutes : 2 Seconds




-------------------------------
Test Evaluation (Backdoor)
-------------------------------

Accuracy        = 0.8158
F1-Score        = 0.4746
Precision       = 0.5000
Recall          = 0.9539
Average Loss    = 1.3291




Final Evaluation
Saving Results ...
Results Saved


100%|##########| 50/50 [02:03<00:00,  3.92s/it]100%|##########| 50/50 [02:03<00:00,  2.46s/it]
Saving Context Weights for Method: 'PALM'

Model saved to /l/users/asif.hanif/models/palm/nbad/SESA-SEED_0-TARGET_0.pth


Time & Date = 10:36 PM , 04_Jan_2025  GST

Total Time => 0 Hours : 2 Minutes : 3 Seconds


